<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Memorize</title>

  <!-- MathJax configuration must come before MathJAX is loaded even if async -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      TeX: {
        extensions: [ "color.js" ]
      }
    });
  </script>

  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_SVG" async></script>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

  <link rel="stylesheet" href="css/tufte.css">
  <link rel="stylesheet" href="css/main.css">

  <link rel="favicon" href="favicon.ico">
  <link rel="shortcut icon" href="favicon.ico">
  <link rel="icon" href="favicon.ico">
</head>
<body>
  <article>
    <div style="display: none">
      $$
        \definecolor{us}{RGB}{239, 168, 86}
        \definecolor{other}{RGB}{74, 179, 193}
      $$
    </div>

   <img src="img/memorize.512.png" alt="RedQueen"
       aria="hidden" class="red-queen-icon" />
    <h1 class="memorize">
        Memorize
    </h1>

    <p class="subtitle">
      An optimal algorithm for spaced repetition
    </p>
    <!--
    <ul class="subtitle">
      <li>Presented at <a href="http://www.wsdm-conference.org/2017/">WSDM, 2017</a>;</li>
      <li>Full paper at <a href="https://arxiv.org/abs/1610.05773">arxiv.org/abs/1610.05773</a>;</li>
      <li>Source code at <a href="https://github.com/Networks-Learning/RedQueen"><i class="fa fa-github"></i>Networks-Learning/RedQueen</a></li>
    </ul>
    -->

    <section>
      <h2>Introduction</h2>

      <p>
        It is <a href="https://www.gwern.net/Spaced-repetition">well known</a> that
        repeated and spaced reviews of knowledge is necessary for improving
        retention.
        However, it is unclear what is the best schedule for reviewing. Several
        heuristics have been suggested, but they lack guarantees of optimality.
          <label class="margin-toggle sidenote-number" for="sn-reviewing"></label>
          <input id="sn-reviewing" class="margin-toggle" type="checkbox">
          <span class="sidenote">
            See <a href="https://www.ncbi.nlm.nih.gov/pubmed/24444515">Lindsey et al</a>, <a href="https://papers.nips.cc/paper/3731-predicting-the-optimal-spacing-of-study-a-multiscale-context-model-of-memory">Pashler et al.</a>, <a href="http://psycnet.apa.org/record/2009-01320-009">Metzler-Baddeley et al.</a>, <a href="https://www.ncbi.nlm.nih.gov/pubmed/18590367">Pavlik et al</a>, <a href="https://arxiv.org/abs/1602.07032">Reddy et al.</a>, etc.
          </span>

        In this work, we will describe a way of coming up with an optimal
        scheduling algorithm which we name <span class="memorize">Memorize</span>.
      </p>

      <h2>Problem setup</h2>

      <p>
        Let us consider the problem of learning <em>one</em> knowledge item.
        We assume that we know how <em>difficult</em> learning the item is.
          <label class="margin-toggle sidenote-number" for="sn-item-difficulty"></label>
          <input id="sn-item-difficulty" class="margin-toggle" type="checkbox">
          <span class="sidenote">
            We will formalize these parameters later. These parameters
            can be estimated from a dataset of learning traces.
            Depending on the size of the dataset, these parameters can be
            user-specific, item-specific, or even user-item specific.
          </span>

        Our algorithm will determine the time the item is to be reviewed by the
        learner. The learner will be <em>tested</em> at that time to see if he
        can recall the item and our algorithm will update our next-reviewing
        time based on that information, <em>adapting</em> to the user.
      </p>

      <p>
        The objective of the algorithm is to keep the recall of the item high
        during the experiment duration \( (0, T] \) while minimizing the total
        number of reviews that the learner has to do.
      </p>

      <h3>Memory models</h3>
      <p>
        Before we can start talking about scheduling, we need a model of human
        memory, which can help us predict how humans forget. There are
        multiple models of memory which can predict the probability of recall
        at time \( t \) given the past reviews of the item and its
        <em>difficulty</em>.

          <label class="margin-toggle sidenote-number" for="sn-memory-model"></label>
          <input id="sn-memory-model" class="margin-toggle" type="checkbox">
          <span class="sidenote">
            See <a href="http://act-r.psy.cmu.edu/">ACT-R</a>, <a href="https://papers.nips.cc/paper/3731-predicting-the-optimal-spacing-of-study-a-multiscale-context-model-of-memory">Multiscale Context Model (MCM)</a>, <a href="https://public.psych.iastate.edu/shacarp/Wixted_Carpenter_2007.pdf">Power-law</a>, etc.
          </span>
      </p>

      <figure>
        <label class="margin-toggle" for="memory-model">⊕</label>
        <input id="memody-model" class="margin-toggle" type="checkbox">
        <span class="marginnote">
          An example of how the probability of recall may change with time.
          As soon as a review happens, the recall probability jumps to \( 1 \).
          It rate of decay depends on the forgetting rate \( n(t) \).
        </span>
        <img class="full-width" src="img/memory-model.png" alt="Samples of schedules">
      </figure>


      <p>
        We will assume that the probability of recall follows the analytically
        simple exponential forgetting curve model. In our paper, we have extended the
        analysis to more widely accepted power-law forgetting curve model of memory as
        well.
      </p>

      <p>
        In the exponential forgetting curve model of memory, we assume that
        probability of recall \( m(t) \) of the item immediately after a review is
        \( 1 \). Then, as the name suggests, the probability of recall
        \( m(t) \) decays exponentially with a forgetting rate
        \( n(t) \), which depends on the past reviews and the item difficulty:

        $$
        m(t) = e^{-n(t)(t - t_{\text{last review}})}
        $$
        <label class="margin-toggle" for="sn-power-law">⊕</label>
        <input id="sn-power-law" class="margin-toggle" type="checkbox">
        <span class="marginnote">
          The power-law forgetting curve model is \( m(t) = (1 + \omega (t - t_{\text{last review}}))^{-n(t)} \), where \( \omega \) is a parameter we
          learn from the data.
        </span>

        Our estimate of the forgetting rate is adapted to be higher or lower
        depending on whether the learner managed to recall the item at a
        review or not:

        $$
        n(t + dt) = \begin{cases}
        (1 - \alpha) \times n(t) & \text{if item was recalled}\\
        (1 + \beta) \times n(t) & \text{if item was forgotten}
        \end{cases}
        $$

        \( \alpha \) and \( \beta \), as well as the initial difficulty \( n(0)
        \),  are parameters of the model which are derived from the dataset
        using a variant of
        <a href="https://github.com/duolingo/halflife-regression">Halflife regression.</a>
      </p>

      <h2>Methodology</h2>

      <p>
        Previous approaches usually directly attempt to produce the optimal
        time to review either by discretizing time into fixed sized slots (e.g. hours or days)
        or by using a <em>thresholding</em> based strategy (which schedules a
        review just when the recall probability falls under a fixed threshold).
        However, instead of optimizing for the exact time of review, we will aim
        at uncovering the optimal <em>rate</em> of reviewing.
      </p>

      <figure>
        <label class="margin-toggle" for="intensity-func">⊕</label>
        <input id="intensity-func" class="margin-toggle" type="checkbox">
        <span class="marginnote">
          The relationship between intensity \( u(t) \) and the number of reviews \( N(t) \).
          When the intensity is higher, the events happen with a <em>higher rate</em>, or
          more frequently.
        </span>
        <img class="full-width" src="img/intensity.png" alt="Intensity function and number of events.">
      </figure>


      <p>
        This change will allow us to formulate the discovery of the optimal reviewing schedule as a <a href="shttps://en.wikipedia.org/wiki/Hamilton%E2%80%93Jacobi%E2%80%93Bellman_equation#Extension_to_stochastic_problems">stochastic control problem.</a>
        However, before that, we have to choose a loss function which the optimal reviewing schedule ought to minimize.
      </p>

      <p>
        We choose the following loss function

        $$
          \begin{align}
          \underset{u(0, T]}{\text{minimize}} &
          \quad \mathbb{E}_{ \{ \text{reviewing times} \} }\left[
                \int_{0}^{T} \left( \,(1 - m(\tau))^2 + \frac{1}{2} q\,u^2(\tau) \right) d\tau
              \right] \\
          \text{subject to} & \quad u(t) \geq 0 \quad \forall t \in (0, T]
          \end{align}
        $$

        This loss penalizes high probability of forgetting \( (1 - m(t))^2 \) as well
        as high review rates \( \frac{1}{2} q\,u^2(t) \), with \( q \) acting
        as a tunable parameter to trade off between these objectives.
      </p>

      <p>
        We integrate the this loss function over the experiment interval
        \( (0, T] \) and, since the reviewing times are stochastic, we attempt
        to find the reviewing rate \( u(t) \) for the item which minimizes the
        expectation of the integral.
      </p>

      <p>
        With this choice of the loss function, the optimization problem can be
        solved analytically by formulating the optimal cost-to-go, deriving a
        PDE using the <a href="https://en.wikipedia.org/w/index.php?title=Hamilton%E2%80%93Jacobi%E2%80%93Bellman_equation&wteswitched=1">Hamilton-Jacobi-Bellman equation</a>
        and then solving it.
      </p>

      <p>
        Finally, on solving the PDE, we arrive at the following elegant solution:

        $$
        \overbrace{u(t)}^{\text{reviewing intensity}} = q^{-{1}/{2}}\,\underbrace{(1 - m(t))}_{\text{Prob. of forgetting}}
        $$
      </p>

      <p>
        This function states that the rate at which the item must be reviewed
        (i.e. the <em>urgency</em> of reviewing), should be proportional to how
        <em>close</em> the learner is to forgetting that item. Hence, the
        <em>urgency</em> to review increases as the recall rate \( m(t) \) drops.
        If the user remembers the item perfectly, i.e.
        \( m(t) = 1 \), the rate at which reviews will happen will be 0, i.e.
        no reviews will be scheduled.

        Similarly, if the user has completely forgotten the item, i.e.
        \( m(t) = 0 \), the learner will see review events with rate
        \( q^{-{1}/{2}} \) per unit of time.
      </p>

      <p>
        Note that this is different from scheduling a review
        after the probability of recall hits a certain threshold. That is a
        deterministic heuristic policy which attempts to prevent the probability
        of recall from falling below a threshold. Our policy, on the other hand,
        is stochastic in nature and is provably optimal for our loss function.
      </p>

      <h3 id="sampling">From <em>rate-of-reviewing</em> to <em>next-review-time</em></h3>

      <p>
        Now that we know the rate at which the item should be reviewed, we have
        to determine when exactly should the next post be made. This can be done
        easily using
        <a href="https://en.wikipedia.org/wiki/Poisson_point_process#Thinning"><em>thinning</em> of Poisson process</a>
        because we know what the maximum reviewing intensity is, i.e. \( q^{-{1}/{2}} \).
      </p>

      <h2 id="evaluation">Evaluation</h2>

      <p>
        To evaluate our scheduling, we used the dataset made available at
        <a href="https://github.com/duolingo/halflife-regression" style="display:inline-block"><i class="fa fa-github"></i> duolingo/halflife-regression</a>.
        First, we determine <em>how close</em> a given schedule is to <span class="memorize">Memorize</span>,
        or any of the baselines, and then we determine what the performance of
        the people who follow each scheduling strategy most closely, i.e. are
        in the top 25%-quantile of using that particular strategy by likelihood.
      </p>

      <figure>
        <label class="margin-toggle" for="scheduling-samples">⊕</label>
        <input id="scheduling-samples" class="margin-toggle" type="checkbox">
        <span class="marginnote">
          Example of traces close to various schedules for the same recall
          pattern (✔, ✕, ✔, ✔). <span class="memorize">Memorize</span> and
          Threshold based strategy have similar looking traces, as they both
          respond to whether the learner got the answers right (next review
          is further away) or wrong (next review closer).

          However, while the scheduling by Threshold is a heuristic, the traces
          generated by <span class="memorize">Memorize</span> are stochastic
          and provably optimal. The Uniform scheduler has even spacing between
          all reviews irrespective of whether the learner was able to recall
          the item or
          not.
        </span>
        <img class="full-width" src="img/baselines.png" alt="Samples of schedules">
      </figure>

      <p>
        We found that the empirical forgetting rate for the learners who
        followed <span class="memorize">Memorize</span>
        for our method was much better than for the other baselines.
      </p>

      <figure>
        <label class="margin-toggle" for="evaluation">⊕</label>
        <input id="evaluation" class="margin-toggle" type="checkbox">
        <span class="marginnote">
          The relative empirical forgetting rate for (item, learners) who follow <span class="memorize">Memorize</span>
          is much lower than for other pairs which follow other baselines.
        </span>
        <img class="full-width" src="img/evaluation.png" alt="Evaluation.">
      </figure>


      <h2>More details</h2>

      <p>
        Our paper contains a mathematical description of <span class="memorize">Memorize</span>,
        and several extensions:
      </p>

      <ul>
        <li>Extending the one item algorithm to multiple items.</li>
        <li>Using the power-law forgetting curve.</li>
        <li>Proof of optimality of the solution.</li>
        <li>More experiments comparing performance of learners who followed <span class="memorize">Memorize</span> like scheduling and other schedulers.</li>
      </ul>


      <h2>Authors</h2>

      <p>
      The authors of <span class="memorize">Memorize</span> are <a href="http://www.btabibian.com/">Behzad Tabibian</a>, <a href="https://musicallyut.in">Utkarsh Upadhyay</a>, <a href="http://cse.iitkgp.ac.in/~abird/">Abir De</a>, <a href="https://azarezade.github.io/">Ali Zarezade</a>, <a href="https://is.tuebingen.mpg.de/de/people/bs">Bernhard Schölkopf</a> and <a href="https://people.mpi-sws.org/~manuelgr/">Manuel Gomez-Rodriguez</a>.

      The webpage was created by <a href="https://musicallyut.in">Utkarsh Upadhyay</a>.
      </p>
    </section>

    <hr>

    <section class="small-font">
      <h3>Acknowledgements</h3>
      <p>
        The <em class="red-queen">Memorize</em> icon was made by <a href="http://www.freepik.com" title="Freepik">Freepik</a> from <a href="http://www.flaticon.com" title="Flaticon">www.flaticon.com</a>. It is licensed by <a href="http://creativecommons.org/licenses/by/3.0/" title="Creative Commons BY 3.0" target="_blank">CC 3.0 BY</a>.

        <!-- Other icons made by <a href="http://www.freepik.com" title="Freepik">Freepik</a> from <a href="http://www.flaticon.com" title="Flaticon">www.flaticon.com</a> are licensed by <a href="http://creativecommons.org/licenses/by/3.0/" title="Creative Commons BY 3.0" target="_blank">CC 3.0 BY</a></div> -->
      </p>
    </section>

    <!--
    <section>
      <h3>Source code</h3>
      <ul>
        <li><a href="https://github.com/Networks-Learning/Memorize"><i class="fa fa-github"></i>Networks-Learning/Memorize</a></li>
        <li><a href="https://github.com/Networks-Learning/Memorize-website"><i class="fa fa-github"></i>Networks-Learning/Memorize-website</a></li>
      </ul>
    </section>
    -->
  </article>

  <script src="js/main.js"></script>
  <script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-8158678-1");
pageTracker._trackPageview();
} catch(err) {}
   </script>
</body>
</html>
